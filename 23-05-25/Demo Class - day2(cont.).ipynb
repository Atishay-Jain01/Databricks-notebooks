{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbb36d3d-6b6b-461f-845f-e9728d788b8c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Sum"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "x = 5\n",
    "y = 10\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d4da209-abe6-4386-8173-05c5f7ddf774",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Print List and its sum"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n15\n"
     ]
    }
   ],
   "source": [
    "list = [1,2,3,4,5]\n",
    "print(list)\n",
    "print(sum(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c85b8894-4141-4a29-b66d-3b7cdeb0246c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Calculate Average"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(list)/len(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbb78f3e-fa33-48c3-b7ed-aaebdb67866d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Print Tuple"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3, 4)\n10\n"
     ]
    }
   ],
   "source": [
    "tup = (1,2,3,4)\n",
    "print(tup)\n",
    "print(sum(tup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3cfbe01-c7f4-4ec2-aa3f-5a6be0b20b1e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6}\n{1, 2, 3, 4, 5, 6, 7}\n{1, 2, 3, 4, 5, 6, 7, 11, 12, 13}\n"
     ]
    }
   ],
   "source": [
    "my_set = {1,2,3,4,5,6}\n",
    "print(my_set)\n",
    "my_set.add(7)\n",
    "print(my_set)\n",
    "my_set.update([11,12,13])\n",
    "print(my_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f3daac1-65a7-4709-a3e6-b10a47c2dcea",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Dictionary"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atishay\ndict_keys(['name', 'age'])\ndict_values(['Atishay', 22])\n"
     ]
    }
   ],
   "source": [
    "dict = {\"name\" : \"Atishay\", \"age\" : 21}\n",
    "print(dict[\"name\"])\n",
    "dict[\"age\"] = 22\n",
    "print(dict.keys())\n",
    "print(dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76020f0e-7f6a-4c10-b220-15f1ccea7a3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- A Spark session is initiated using SparkSession.builder\n",
    "- A list of tuples is passed to createDataFrame, defining column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1372d1d4-c2cb-4401-9ea4-6e48485aa8fe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "PySpark"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n| id| name|\n+---+-----+\n|  1|Alice|\n|  2|  Bob|\n|  3|Carol|\n+---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"PythonDF\").getOrCreate()\n",
    "# Creating DataFrame from list of tuples\n",
    "data = [(1, \"Alice\"), (2, \"Bob\"), (3, \"Carol\")]\n",
    "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1322a98b-de44-44e8-b842-9cea6ba4fb37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Basic Transformations and Actions on DataFrames\n",
    "\n",
    "- `select()` returns specified columns.\n",
    "- `filter()` applies row-level conditions.\n",
    "- `count()` returns the number of rows.\n",
    "- `describe()` gives stats like count, mean, stddev, min, max.\n",
    "- `withColumn()` adds or modifies a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dde04b0-0ef3-48c4-b77a-72377db7f7bc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Using above functions"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2843992038415048>:2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Select specific columns\u001B[39;00m\n",
       "\u001B[0;32m----> 2\u001B[0m df\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mshow()\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Filter rows\u001B[39;00m\n",
       "\u001B[1;32m      5\u001B[0m df\u001B[38;5;241m.\u001B[39mfilter(df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-2843992038415048>:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Select specific columns\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m df\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Filter rows\u001B[39;00m\n\u001B[1;32m      5\u001B[0m df\u001B[38;5;241m.\u001B[39mfilter(df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mshow()\n\n\u001B[0;31mNameError\u001B[0m: name 'df' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'df' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select specific columns\n",
    "df.select(\"name\").show()\n",
    "\n",
    "# Filter rows\n",
    "df.filter(df[\"id\"] > 1).show()\n",
    "\n",
    "# Count rows\n",
    "print(df.count())\n",
    "\n",
    "# Describe summary statistics (numeric columns)\n",
    "df.describe().show()\n",
    "\n",
    "# Add new column with literal value\n",
    "from pyspark.sql.functions import lit\n",
    "df = df.withColumn(\"country\", lit(\"India\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3949e4dd-1d24-4d32-969d-004d13e8edf9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Total Revenue per Product"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+---------+--------+-------+\n|      date|region|  product|quantity|revenue|\n+----------+------+---------+--------+-------+\n|2024-01-01| North|Product A|      10|  200.0|\n|2024-01-01| South|Product B|       5|  300.0|\n|2024-01-02| North|Product A|      20|  400.0|\n|2024-01-02| South|Product B|      10|  600.0|\n|2024-01-03|  East|Product C|      15|  375.0|\n+----------+------+---------+--------+-------+\n\n+---------+-------------+\n|  product|total_revenue|\n+---------+-------------+\n|Product A|        600.0|\n|Product B|        900.0|\n|Product C|        375.0|\n+---------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, sum\n",
    "\n",
    "sales_data = [\n",
    "    (\"2024-01-01\", \"North\", \"Product A\", 10, 200.0),\n",
    "    (\"2024-01-01\", \"South\", \"Product B\", 5, 300.0),\n",
    "    (\"2024-01-02\", \"North\", \"Product A\", 20, 400.0),\n",
    "    (\"2024-01-02\", \"South\", \"Product B\", 10, 600.0),\n",
    "    (\"2024-01-03\", \"East\",  \"Product C\", 15, 375.0),\n",
    "]\n",
    "columns = [\"date\", \"region\", \"product\", \"quantity\", \"revenue\"]\n",
    "sales_df = spark.createDataFrame(sales_data, columns)\n",
    "sales_df.show()\n",
    "\n",
    "total_revenue_per_product = sales_df.groupBy(\"product\").agg(  \n",
    "    sum((\"revenue\")).alias(\"total_revenue\")  \n",
    ").show()\n",
    "\n",
    "# sales_df.printschema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7874c0b9-f415-42cc-8059-f6f466612b92",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Total Quantity by Region"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n|region|by region|\n+------+---------+\n| North|       30|\n| South|       15|\n|  East|       15|\n+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_qty_region = sales_df.groupBy(\"region\").agg(sum(\"quantity\").alias(\"by region\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "870f78fe-96e7-4150-9b41-79bd6e43fce5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Average Revenue per Product"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------+\n|  product|Avg_revenue_per_product|\n+---------+-----------------------+\n|Product A|                  300.0|\n|Product B|                  450.0|\n|Product C|                  375.0|\n+---------+-----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "avg_reveue_per_product = sales_df.groupBy(\"product\").agg(avg(\"revenue\").alias(\"Avg_revenue_per_product\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3511f82a-96b0-43e6-ac7f-5838c8d9921e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Highest Revenue of all"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n|region|by region|\n+------+---------+\n| South|    900.0|\n+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "highest_revenue = sales_df.groupBy(\"region\").agg(sum(\"revenue\").alias(\"by region\")).orderBy(\"by region\", ascending=False).limit(1).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Demo Class - day2(cont.)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}